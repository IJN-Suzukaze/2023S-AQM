---
title: "R-Script_DataManipulations"
author: "Nico Wiegand"
date: "11/20/2020"
output: html_document
---

##################################
### Keyboard Shortcuts ###########
##################################
```{r}
# Cmd + option + i = insert new code chunk
# Cmd + shift + enter = run current code chunk
# Cmd + shift + m = pipe operator %>% 
# option + n = Tilde (~)
# Cmd + shift + k = knits the document in r markdown


# echo = FALSE: Hide the code, but run code and produce all outputs, plots, warnings and messages.
# eval = FALSE: Show code, but do not evaluate it.
# fig.show = "hide": Hides plots.
# include = FALSE: Runs code, but suppresses all output. This is helpful for setup code. You can see an example of this in the first code chunk when you open a new R Markdown document!
# message = FALSE: Prevent packages from printing messages when they load. This also suppress messages generated by functions.
# results = "hide": Hides printed output.
# warning = FALSE: Prevents packages and functions from displaying warnings.

```

##################################
######### Set up R ###############
##################################
```{r}
# Which R Version do I have? 
R.version.string

# Update R Packages
update.packages()

options(mc.cores = parallel::detectCores()) #parallel computing
options(max.print = 100000) #print a large number of rows when using the "print" command

```


##################################
########## Data Import ###########
##################################
```{r}
library(readxl)
library(data.table)
detach(package:<name>, unload=TRUE) #detaches the package from the current R run
setwd("/Users/nico.wiegand/Dropbox/Gildemeister Projekt/09 Revision/1_Modeling") #sets the working directory

data1 <- read_excel("C:/Users/wmc640/Documents/R/2_QuantAppMarketing/4_GuestFirst/GuestFirst.xlsx", sheet=2) #import excel-file
data2 <- read.table("C:/Users/wmc640/Documents/R/2_QuantAppMarketing/1_Store24/Store24(A)_data.txt", header = TRUE, dec = ".") #import txt-file
data3 <- read.csv()
data4 <- fread("C:/Users/wmc640/Dropbox/01_Letchkov/06 Forschung/.../Autos_Print.csv", skip=12, na.strings=c("","NA"),dec=',') #from package "data.table"; skips first 12 lines, replaces all empty strings with NAs
data5 <- read.xls("/Volumes/GoogleDrive/.shortcut-targets-by-id/1a4irumAyLus1Q9kqy2vFiXF0_1g5EX1-/5_Context Factors Across Media Channels/3_Data/6_Datenaufbereitung_GetraÌˆnke/BeerBrands.xlsx")
```

##################################
########### Data Types ###########
##################################
```{r}

# (1) Data Types: Vector, Matrix, List, Dataframe
vector <- c(1,2,3,4,5,6) #creates an empty vector; also scalars are treated as vectors in R, there is no type "scalar", but just vector; vectors can just contain one data type (num, logical, chr)
vector <- c(vector, 7) #adds to the vector another element
matrix <- matrix(nrow=4, ncol=6) #creates an empty matrix with 4 rows and 7 columns; matrices are just vectors with multiple dimensions; they need to have the same data type within the matrix (logical, integer, numerical, character)
lists <- list(1,"a",list(2,3,4))   #content of a list is not constrained to the same type (as in vectors and matrices) and can also be other lists; contents can be received by using: [[]]
dataframe <- data.frame() #creates an empty dataframe; dataframe is a special kind of list where each element has the same length
dataframe <- data.frame(matrix(nrow=4, ncol=6)) #creates empty dataframe with 4 rows and 7 column

dataframe <- cbind(x) #binds a vector to a dataframe (=adds another column to the dataframe)

#Create a non-empty dataframe with data you already have
# Assign names to x 
x <- c( "Calvin", "Chris", "Raj")
# Assign names to y
y <- c( 10, 25, 19)

z <- data.frame( "Name" = x, "Age" = y) #creates a dataframe with one column called "Name" and the other one "Age" with all values in there
#Naming rows and columns
naming <- c("One","Two","Three","Four","Five","Six")
names(vector)<- naming 
colnames(matrix) <-naming #names the columns of the matrix
rownames(matrix) <- example #names the rows of the matrix
colnames(data) <- naming #names the columns of the data frame

#Indexing
#If I have a list, I can access each list element by double brackets:
S = 3
N = 5
M = 2
listing <- list()
for (s in 1:S){
  listing[[s]] = matrix(rnorm(N*M), N, M) #This is a list of 4 elements, each of which contains a matrix with N*M elements
}
listing[1] #shows the entire list element 1 (first matrix in the list)
listing[1][1:3,] #gives an error, because we cannot access the matrix using the single brackets
listing[[1]][1:3,] #to access the elements of the first list entry, I need to use double brackets

# (2) Vector & Matrix (+ Arrays) - List & Data Frame
vector <- c(1,2,3,4,5,6) #creates an empty vector; also scalars are treated as vectors in R, there is no type "scalar", but just vector; vectors can just contain one data type (num, logical, chr)
matrix <- matrix(nrow=4, ncol=6) #creates an empty matrix with 4 rows and 7 columns; matrix is just a vector with dimensions

# There are also multidimensional matrices, which are then called arrays (BUT: same rules as matrices, especially only same data type and # columns/rows)
xb <- array(dim=c(tnew,ncol(xb_questions),equations)) #important: the last (!!!) argument is the list dimension (e.g., 50, 10, 2) creates two lists with matrices of dimensions 50 (rows) x 10 (columns) -> only works for equal number of rows and columns in the matrices within the array list (otherwise ust list()) >>> to put it into Stan in the right order, though, we would need to reverse the array dimensions, which is also easily done in R - the order is not strict
array <- array(dim=c(nGroups,max(tPoints),nPredictors)) #creates empty 3-dimensional matrix (=array)
array <- array(0, dim=c(a, b, c) #creates an array with zeros
for (IV in 1:nPredictors){ #puts all the predictors (except the group predictor "Console") into an array with three dimensions (6 groups(N), t time points, 25 IVs)
  countX <- 1
  predictor <- predictorNames[IV+1]
  xmethelp <- matrix(nrow = nGroups,ncol = max(tPoints))
  for (consolex in 1:nGroups){
    xmethelp[consolex,1:tcounts[consolex]] <- panel1[[predictor]][countX:((countX-1)+tcounts[consolex])]
    countX <- countX+tcounts[consolex]
  }
  array[,,IV] <- xmethelp #you can access an array by using the number of dimensions within the []
}

list1 <- list(1, "a", TRUE, 56) #a list is a vector that can store different formats
list2 <- vector(mode="list", length=5) #alternative way to create an empty list, telling it directly how many elements it should have
dataframe1 <- data.frame() #creates an empty dataframe;content of a list is not constrained to the same type (as in vectors and matrices) and can also be other lists; contents can be received by using: [[]]
dataframe2 <- data.frame(matrix(nrow=4, ncol=6)) #creates empty dataframe with 4 rows and 7 columns; you can convert a matrix to a dataframe and thereby create one
frame <- cbind(x) #binds a vector to a dataframe
data_table <- data.table() #creates an empty data.table object (from the data.table package)

### Different manipulations of data containers #################################################
#Create a non-empty dataframe with data you already have
# Assign values to vector x 
x <- c( "Calvin", "Chris", "Raj")
# Assign values to vector y
y <- c( 10, 25, 19)
# Assign names to 
z <- data.frame( "Name" = x, "Age" = y) #creates a dataframe with one column called "Name" and the other one "Age" with all values in x and y
#Naming rows  columns
naming <- c("One","Two","Three","Four","Five","Six")
vector <- c(1,2,3,4,5,6)
names(vector)<- naming 
colnames(matrix) <- naming #names the columns of the matrix
rownames(matrix) <- example #names the rows of the matrix
colnames(data) <- naming #names the columns of the data frame

#Creating a new column
#Data.table always works with the same syntax: data[selection of rows, columns and operations on the columns, by=aggregation variables]
dat[, npur := .N, by=customerId] #creates a new column "npur" that merges together all identical customer IDs; .N means all columns
#Create a vector of repeated values
rep(c(0, 0, 7), times = 3)
#Create a new dataframe with a specific # of rows and columns and name these using two vectors of names
Kantar_Matrix <- data.frame(matrix(ncol=length(UniqueWeeks$DATE), nrow=length(UniqueGames$PRODUCT))) #create dataframe with columns as dates and rows as games
colnames(Kantar_Matrix) <- UniqueWeeks$DATE
rownames(Kantar_Matrix) <- UniqueGames$PRODUCT
#Set dataframe to a tibble (data.table)
setDT(data1)

#Transform a list into a vector
xboxone_name <- as.vector(unlist(xboxone_name))

#Changing variable classes for several variables at the same time
disney_synth <- data.frame(y, w_out, t_fix, tw_fix, x1, x2) #creates data frame
col_names <- c("w_out", "t_fix", "tw_fix") #creates name vector
disney_synth[col_names] <- lapply(disney_synth[col_names], factor) #converts all columns to factors


#Changing a vector into a comma-separated string
paste(as.character(factorVariables), collapse=", ") #factorVariables is the vector

```

#####################################
###### Renaming and Replacing #######
#####################################
```{r}
# Rename and replace
names(data1)[1] <- "Hotel" #renaming single columns with index (base R)
names(data1)[names(data1)=="Property"] <- "Hotel" #renaming single columns with variable name (base R)
names(data1) <- c("Hotel", "Jahr", "Umsatz", "UmsatzCompetitor", "Loyalit?t") #renaming all of the columns (base R)
## Replace things with NAs
disney2 <- disney2 %>% na_if(-66) #replaces -66 with NA

## Remove NaN (Not a Number) from the dataframe
is.nanDF <- function(x) {
do.call(cbind, lapply(x, is.nan))}
oscDataWeeklyTemp[is.nanDF(oscDataWeeklyTemp)] <- 0 #replaces with zero

## Remove NAs from the dataframe
data[is.na(data)] <- 0 #replaces with zero

###DPLYR
rename(data1,Hotel=Property) #renaming single columns with variable names (dplyr); Newname = Oldname
rename(data1,Newname1=OldName1, Newname2 = OldName2) #renaming multiple columns with variable names (dplyr)
data1 %>% rename_at(vars(starts_with("Arr")), funs(str_replace(., "Arr", "Arrival"))) #rename_at renames words in multiple columns that are all the same
data1 %>% rename_all(list(~make.names(.))) #(dpylr) makes column names "appropriate" variable names so that we can use them in all expressions; the (.) means that we apply it to ALL columns; rename_all() is used to change all columns in the same way, no matter what their original names

str_replace_all("BMW GROUP, MUC", "BMW") #replaces all strings in the table "BMW GROUP, MUC" with the string "BMW"
ifelse(substr(auto_print$Produkt, 1,5)=="SMART","SMART", auto_print$Firma) #substr is like "Teil()", "Links()", oder "Rechts()" in Excel; it takes from the column those cells whose strings 1-5 is "SMART" and then replaces them with another string
substr(rickHardwareSoftware$date, 1,7) %>% str_replace_all("-","") %>% as.numeric() #Takes a date and cuts of the days (only year-month)

auto_print[is.na(auto_print)] <- 0 #replaces all NAs with zeros

          ### BETWEEN AND LIKE AND IN
          Data[brand_value %between% c(7,9)] #selects all cells with brand values 7<=x<=9
          Data[brand_name %like% "Spex"] #selects all cells with the string "Spex" within the cell
          Data[origin %in% c("JFK", "LGA")] #selects all rows where the column origin shows JFK OR LGA

names(beer_digital) = gsub(pattern = "\\.DE", replacement = "", x =names(beer_digital)) #finds the pattern in the column names and replaces them with nothing
beer_tv <- cbind(beer_tv[,1:(grep("^Werbetraeger$", colnames(beer_tv)))],beer_tv[,lapply(.SD, function(x) gsub(pattern="\\.", replacement = "",x)),.SDcols = week_vector])#all data is read in as character; we need to convert to numeric, but R regards "." as a comma, which is why we need to replace them first

### DATA.TABLE
print_deletion <- c('BILD.AACHEN', 'BILD.SONDERAUSG..HEIMAT')
beer_print <- beer_print[,!print_deletion, with=FALSE] #deletes from the data.table the columns in "print_deletion"

xboxone_r <- trimws(xboxone_r) #gets rid of spaces between words

#Comparing whether vectors are the same
setdiff(i, j) #outputs the vector places which are not identical between the two vectors

#Concatenating Strings (wie Verketten in Excel)
autoTV$Woche <- ifelse(nchar(autoTV$Woche)==1,paste("0", autoTV$Woche, sep=''),autoTV$Woche) #if the cell includes only 1 digit, then add a "0" before it


```



#####################################
## Filtering, Selecting, Mutating ###
#####################################
```{r}
# Filter data rows > I would normally take dplyr for this
filtered1 <- subset(data1, data1$Property==5) #(base R) cuts out specific rows from a data frame
filtered1 <- filter(data1,Property==5) #(dplyr) cuts out specific rows from a data frame
filtered1 <- filter(ricardo3, grepl('uhren|Uhren', Level3)) #filters from the data ricardo3 those rows which contain "uhren" or "Uhren"
filtered1 <- data1[origin=="JFK"] #(data.table) cuts out the rows of origin that have "JFK" in the cells
filtered1 <- data1[origin %in% c("JFK", "CGN")] #(data.table) cuts out multiple rows, i.e., all those with JFK or CGN in the cells
brands <- c("AUDI AG, INGOLSTADT", "BMW, MUC","BMW GROUP, MUC") #creates brand vector to filter from
auto_print <- filter(auto_print_raw, Firma %in% brands) #(dplyr) filters out all brands in the brand vector; needs %in%, because otherwise (with ==) it goes through the vector and only keeps every 26th row

# Select data columns > I would normally take dplyr for this
selected1 <- subset(data1,select = c(Property,Year)) #(base R) cuts out specific columns from a data frame
selected1 <- select(data1,Property,Year) #(dplyr) cuts out specific columns from a data frame; help functions: starts_with(), ends_with(), matches(), contains()
selected1 <- data1[,.(origin)] #(data.table) selects only the column "origin"; The "." is important because it makes the function return a data.table instead of a vector 
selected1 <- data1[,.(origin, date, airline)] #(data.table) selects multiple columns

  # Select a set of columns specified in a vector
  columns_to_sel = c("productId", "customerId", "BidDate", "AuctionType")
  data = data[, (columns_to_sel), with=FALSE]


# Delete/Remove data columns
xboxone <- xboxone[-c(7,14,17,20,24,28,32,36,40)] #deletes the column numbers
remove <- c("VGChartz Score: ", "Critic Score: ", "User Score: ", " Inc  ", " Inc.  ") #creates vector for deletion of cells
xboxone_pub <- xboxone_pub[! xboxone_pub %in% remove] #removes all cells that include the words in "remove"

# Add new columns > I would use data.table for this, as we can calculate anything very easily for new columns
data1$NewColumn <- c(1,2,3) #(base R) creates a new column with repeating 1,2,3 until end row
data1$NewColumn <- data1$Property - data1$Year #(base R) creates a new column as a function of two existing columns
data1[NewColumn:= c(1,2,3)] #(data.table) creates a new column with the package data.table; the ":=" is only used when adding new columns
data1[c(NewColumn1, NewColumn2):=list(calculation1, calculation2)] #(data.table) creates two new columns, each from unique operations within the list
data1mutate <- mutate(data1, NewColumn = Property - Year, NewColumn2 = Year + Year) #creates a new column as a function of two existing columns (dyplr)
data1mutate <- mutate_if(is.numeric, round, digits = 2)
data1mutate <- transmute(data1,NewColumn = Property - Year, NewColumn2 = Year + Year) #creates a new column and cuts it out (dyplr)
oscDataWeeklyTempTest <- oscDataWeeklyTemp %>% mutate(var = 1) %>% spread(month, var, fill = 0, sep = "_") #creates dummies from factor variables (dplyr)

software <- software %>% mutate(Immersion = apply(select(.,c("Immersion1","Immersion2")),1,mean)) #If I want to calculate means, this is more difficult, as the base function would try to calculate one mean out of all observations instead of doing it per row
software <- software %>% mutate(newconsole = ifelse(Scenario==1,1,0), oldconsole = ifelse(Scenario==2,1,0), handheld = ifelse(Scenario==3,1,0), mobile = ifelse(Scenario==4,1,0)) #Create dummy variables from a one-factor variable

# Only keep unique rows based on column duplicates
my_data <- my_data %>% distinct(ArticleNr, .keep_all = TRUE) #dplyr; keeps all columns in new dataset but selects only unique rows based on ArticleNr

# Applying a function per group of variables, e.g., counting 
da_bq = da_bq[, ":=" (NumberBids = .N), by = ArticleNr] #(data.table) calculates the number of bids per Article and inserts them in a new column "NumberBids"

#mutate SpezialfÃ¤lle
auto_print<- mutate(auto_print, !!name:=eval(parse(text=equation))) #so kann man dynamisch Spaltennamen generieren und berechnen: !!name = nutzt einen gespeicherten String in der Variable "name" und sagt R, dass dieser String als Variable interpretiert werden soll; eval(parse(text=equation)) = evaluiert eine Gleichung, die als String gespeichert ist, z.B. (equation <- "1+9")

#Rearrange Columns in Data Frame
#Just use "Select" (dplyr) to create a new dataframe
handheldHardware %>% select(yearMonth, salesMonth, productID, productName, Platform, Publisher, Franchise, UPC, Units, Revenue) -> handheldHardware #creates a new dataframe with a new order of the columns

consoleSoftwareGame <- consoleSoftwareGame %>% relocate(month_id, c_platform, game_name, game_id, season, trend, game_publisher, game_developer, franchise, ip, new_ip, existing_ip, sequel, genre, sub_genre, esrb_rating, game_units, game_revenue) #reorders the columns that are mentioned without altering the order of the remaining ones (dplyr)

#Creating "NAs" from strings that are not recognized as true NAs
xboxone_sales <- xboxone_sales %>% na_if("N/A")

# Create a Trend variable
  oscDataWeeklyTemp$trend <- c(0) #creates a zero vector
  start <- as.integer(grep("04-Oct-2015",oscDataWeeklyTemp$date)) #start row
  end <- as.integer(grep("30-Sep-2018",oscDataWeeklyTemp$date)) #end row
  t <- 1
  for (i in start:end) {
    oscDataWeeklyTemp$trend[i] <- t #loop to count from 1 to X
    t= t+1
  }

  
  
relocate(VarName1, VarName2, etc.) #reorders the variables in your dataframe
rename(newName = oldName) #renames variables in your dataframe
revalue("old value"="new value") #changes strings to other strings

sum(data$adopters==0) #zÃ¤hlenwenn die Variable Adopters den Wert Null annimmt


```


#########################################
## Joining, Gathering, Spreading Data ###
#########################################
```{r}
###Joining and Splitting
data1stacked <- data.frame("Property"=c(data1$Property,data1$Year)) #stacks two columns on top of each other
data <- left_join(table1, table2, by=ID) #(dplyr) SVERWEIS function in r: there are several join function in dplyr
data3 <- merge(data1, data2, by=Level2) #(base R) merges two data frames by a common column name; if column names of ID are different in the two tables, use by.x and by.y; like left_join
xboxone_date <- unlist(strsplit(xboxone_date, "  ,")) #splits the strings based on " ," pattern; like "Daten von CSV einfÃ¼gen" in Excel

###Gathering and Spreading
data <- gather(data1, '1999','2000',key="year", value = "revenues") #(dplyr) gathers 2 columns (1999, 2000) under the variable "year"
data <- unite(Kantar_All, col=YEARWEEK, YEAR,WEEK, sep="", remove=FALSE) #(tidyr) combine from dataframe "Kantar_All" YEAR and WEEK in a new column YEARWEEK and keep the old ones
data <- spread(data1, key="type", value="revenues") #(dplyr) gathers 2 rows and puts each one in a column; complement of gather-function
data <- separate(data1, columnname, c("newcol1","newcol2"), sep=3) #(tidyr) separates a cell that mixes two values (e.g., sex and age: m31) into two columns; similar to "spread"
data2 <- data1 %>% separate(sexage, c("sex", "age"), sep = 1) #example for "separate": column "sexage" into "sex" and "age" after the first character

###MELT AND DCAST (changing tables from long to wide format and vice versa; like Excel's Pivot Tables)
data <- melt(auto_print, id.vars=c("Firma", "WerbetrÃ¤ger"), measure.vars=week_vector, variable.name="Week", value.name="Adspend") #melts the table from wide to long (puts Weeks together in one column and aggregates all ad spending for identical weeks separate for each Firma and Werbetr?ger combination; weekvector is a name vector of all column names, which are the weeks 20161, 20162,...20195)
data <- dcast(auto_print, Firma + Week ~ WerbetrÃ¤ger, value.var = "Adspend") #disperses the "Umfelder" to the columns to bring the table in the right format

# Create buckets (factors) from numerical or character values
Invia_Out$traveltime_groups <- cut(Invia_Out$traveltime, 
                                   breaks = c(-Inf, 7, 11, 15, 21, Inf), 
                                   labels = c("<7 days","7 to 10 days","11-14 days", "15-21 days","> 21 days"), 
                                   right = FALSE) #creates buckets of travel days depending on the continuous numbers of traveldays in the original data
oscDataWeeklyTemp <- oscDataWeeklyTemp %>% mutate(var = 1) %>% spread(season, var, fill = 0, sep = "_") #creates dummies from factor variables (dplyr)
```


#########################################
######### Regular Expressions ###########
#########################################
```{r}
grep("^Werbetraeger$") #The ^ means that it looks for the beginning of a line, so everything that begins with "Werbetraeger; would not match if Werbetraeger occurs somewhere in the middle of a line
grep("^Werbetraeger$") #The $ means the end of a line; so everything that ends with Werbetraeger is picked
grep("[Bb][Uu][Ss][Hh]") #The [] mean that I accept both a capital and a lower-case letter when looking for my string "Bush"
grep("[a-zA-Z]") #Means any upper case or lower case letter
grep("[^.?]$") #Inside brackets, the carrot ^ takes on a different meaning: it means I want to select all strings that DO NOT end on a . or ? (end because of the $)
grep("11.9") #The . means "any character"; so this would match 9/11 or 9.11 or 9K11 or even nothing: 911
grep("(.*)") #The * means that the preceding character is repeated any number of times (including no times): so here we are looking at any expression in parentheses

grep() #returns the index of where a match is found
grepl()#grepl() returns a TRUE/FALSE vector indicating which elements of the character vector contain a match

#Search a character vector for regular expression matches and return the indices of the string where the match begins and the length of the match
regexpr() #just gives you the first match in a sequence
gregexpr() #gives you all the matches in a sequence

#Substitution of strings based on regular expressions
sub() #Only replaces the first match
gsub() #Search a character vector for regular expression matches and replace that match with another string; replaces all found matches

regexec() #This function searches a character vector for a regular expression, much like regexpr(), but it will additionally return the locations of any parenthesized sub-expressions. Probably easier to explain through demonstration.
```


#########################################
########### FLEXIBLE LOOPS ##############
#########################################
```{r}
#The PASTE and QUOTE functions: paste puts together the stated arguments in one cell using different specified joints (, ; and)
#We need this if we want to save an expression as an equation that can later be evaluated by another function (so save equations as a string)
paste(c(1,2,3,4), collapse='and') #creates the following cell: "1 and 2 and 3 and 4"; wie "Verketten" in Excel
paste(c('X','Y'),1:5,sep='_',collapse=' and ') #gives "X_1 and Y_2 and X_3 and Y_4 and X_5"
quote(y <- x * 10) #this saves the formula as an expression (not a string); EXPRESSION = an object that represents an action that can be performed by R
paste("x","*","10") #this saves the formula as a string

consoleSoftware$genre <- paste0(as.vector(consoleSoftware$gen_bro_old), as.vector(consoleSoftware$gen_bro_new)) #concatenates strings in a cell from two different columns

for (i in 1:5){
  software[,paste("HorizontalDiff",i,sep='_')] <- software[,paste("HorizontalDiff",i,sep='_')]-7
} #loops through the columns starting with HorizontalDiff_1 and assigns the original values -7

###How to evaluate equations if they are given as expressions or strings
eval(substitute(a+b)) #eval evaluates the expression that is given to it; substitute puts the expression a+b in the right format to be evaluated
eval(parse(text="a+b")) #evaluates a string; parse is the string-equivalent to "substitute" 

# Problem des Durchloopens bei data.table Objekten: es nimmt einen einfachen String nicht als Spaltenbezeichnung; in a data frame, we can just access an element by calling its name as a string: data[, "sales"]. We could also do this if we assign the column name to a variable, e.g., var1 <- "sales" >>> data[, var1]. This is not possible with a data.table object, because it does not recognize the string
# EXAMPLES
for (i in 1:length(mediaServices)) {
  nam <- paste(mediaServices[i],"Use", sep="")
  texts <- paste(mediaServices[i],"use", sep="_")
  assign(nam, disney %>% count(disney[,texts, with=F]) %>% mutate(share=prop.table(n))) #man muss with=F hinzufÃ¼gen, damit data.table den String richtig interpretiert
}
for (i in 1:length(print_merge)){
  equation <- paste(print_merge[[i]], collapse="+") 
  name <- paste(print_merge[[i]][1],"Gesamt", sep="_")
  beer_print<- mutate(beer_print, !!name:=eval(parse(text=equation))) #sum up all values from the different columns
  setDT(beer_print) #sets the data.frame back to data.table (because using dplyr has converted the data.table object to a dataframe)
  beer_print <- beer_print[,!print_merge[[i]], with=FALSE] #get rid of the columns I don't need anymore (data.table)
} 

```

#########################################
########## Grouping & Descriptives ######
#########################################
```{r}
#Group By...
Kantar_All <- Kantar_All %>% group_by(PRODUCT,YEAR_MONTH) %>% summarize(ADSPEND=sum(`TOTAL DOLS`),BRAND=BRAND[1],DATE=max(DATE), YEAR=YEAR[1], MONTH=MONTH[1], MONTH_WEEK=max(MONTH_WEEK))

redemptionHistogram <- indulgence_1 %>%  group_by(redemptionShare) %>% summarize(absolute = n()) %>% ungroup() %>% mutate(total = sum(absolute), relative=absolute/total, cumulative = cumsum(relative))  #summarizes by the number of redemptions that each customer has made (e.g, 1 redemption, 2 redemptions, etc.), calculating the share of these redemptions relative to all visits, and gives the cumulative distribution (cumsum)

redemptionHistogram3 <- redemptionHistogram2 %>% mutate(bucket = cut(relRedemptions, seq(min(relRedemptions), max(relRedemptions) + .1,.1), right = FALSE)) %>% group_by(bucket) %>% summarize(summe = n()) %>% ungroup() %>% mutate(total=sum(summe), relativ=summe/total, kumuliert=cumsum(relativ)) -> redemptionHistogram3 #kreiert zunÃ¤chst "buckets" von Beobachtungen, gruppiert dann auf Basis der Buckets, und gibt relative und kumulierte Distributionen aus.

#Create a table of occurrences of each factor level
disney %>% count(netflix, amazon) #gives a table with 0 (no neflix/amazon) and 1(yes netflix/amazon) and counts occurrences
disney %>% count(disney) %>% mutate(share=prop.table(n)) #adds shares to the counts

#Use a vector of variables 
factorVariables <- c('matrix1_warrnosuccessno', 'matrix1_warrnosuccessyes',
                     'matrix1_warryessuccessno', 'matrix1_warryessuccessyes',
                     'segmentab',
                     'training', 'joiner', 'leaver', 'statusarr_agg3', 'recentpayout30_dummy')
sapply(DMG_descr[factorVariables], table) #problem with count(): all interactions are counted; here, only 1/0 per variable; 

#Count the number of occurences of each factor
DMG %>% group_by(field_hotline) %>% summarise(numberrows=length(field_hotline))
sum(handheldSoftware$IP == "Existing IP") #counts the number of occurences within the Variable "IP"

#Analyze only part of a data frame or give out descriptives only for part of it
corMatrix <- oscDataWeekly %>% select(trend,focal_calls, focal_mails, control2_calls, control2_mails, community_questions, community_questions_cum, community_likes, community_likes_cum, community_new_users, community_page_views, community_page_views_cum) %>% cor()


#Print more than 10 rows of a Tibble
print(redemptionHistogram, n=40)

```

#########################################
########## Exporting Dataframes #########
#########################################
```{r}
write.csv(oscDataWeeklyWide, "/Users/nico.wiegand/Dropbox/Community Paper/3_Data/Quant Daten/4_DataNico/oscDataDailyWide.csv")
```


#########################################
######### Special Functions #############
#########################################
```{r}
###Changing date formats
require(lubridate) #package to easily convert dates
Invia1[,c("arrival_timestamp", "return_departure_timestamp")]<- lapply(Invia1[,c("arrival_timestamp","return_departure_timestamp")],dmy_hm)
Invia1 <- Invia1[,traveltime:=round(difftime(return_departure_timestamp,arrival_timestamp, units="days"))] #take the difference of return and arrival times and round them to days
Invia1 <- Invia1[,traveltime:=ifelse(traveltime==365,1,traveltime)] 


# Creating own FUNCTIONS
naSub <- function(frame, column) {  
  x <- as.vector(frame[,column])
    for (i in 2:nrow(frame)) {
      if (is.na(x[i])==TRUE) {
      x[i] <- x[i-1]}
      }
  return(x)
} #This function takes a dataframe and a column name to use these in a copy of a lagged value if the current value is NA
# The thing is that everything that happens in a function, stays in a function - so we have to then assign this to the original dataframe again for the new column to show up there
handheldSoftwareGame$gamePublisher <- naSub(handheldSoftwareGame,"gamePublisher") #replaces the game publisher everywhere there is an NA in a cell

# Probleme mit if und ifelse
if (X<0) {
  then what
} else {
  something other    #the thing here is that the if...else statement is not vectorized, but can be used to loop through a list or compare single values. If we have input vectors of logical statements (true/false), it will only use the first comparison
}                   

ifelse(condition, then, otherwise) #ifelse IS vectorized and can take care of the problem of if...else; however, it is only vectorized correctly (=assigning each value in one column the corresonding value in another column, if all vectors of condition, then, otherwise have THE SAME LENGTH! Otherwise, it just reduces the statement to the shortest length column); therefore, if I want to e.g. replace a cell in column C if the conditions in columns A and B are met together, and otherwise leave the cell as it is, then I need to create a vector for each column with all replacement values:
rueckvector <- rep(100, nrow(disney2)) # I need this vector of 100s, because I cannot just insert 100 in the "then" statement because then the otherwise statement is wrongly inserted
disney2 <- disney2 %>% mutate(!!timing := ifelse(disney2[,useCounts]==1 & disney2[,nam]==1,rueckvector,disney2[,timing])) #the double !! unquotes a string and thus lets dyplr interpret it as a variable name


#### Calculating lagged values of a variable
lg <- function(X) { 
  if(length(X)==1){
    return(X)
  } else {
    return(c(X[1], X[1:(length(X)-1)])) #takes the entire vector per customer ID and outputs a new, lagged vector: first element stays the same, the other elements are -1
  }
}

#### Calculating differenced values of a variable
ipti <- function(X) { 
  if(length(X)==1){
    return(0)
  } else {
    return(c(0, diff(X))) #first element of the vector is zero, the other elements are always the differences
  }
}

#>>> these functions can be used with data table's "by = CustomerID" to go through a dataframe and add lags and differences of variables per group



```

#######################
###### ggplot2 ########
#######################
```{r}
### Create a line diagram over time with different time series and manual coloring
callComparison <- 
  ggplot(data=oscDataWeeklyWide) + #global plot settings
                geom_line(aes(y=focal_calls, x=ymd, colour="focal_calls")) +
                geom_line(aes(y=control2_calls, x=ymd, colour="control2_calls")) + 
                scale_color_manual(name="Business Units", #sets customized coloring and labeling options to the legend
                                   values=c("focal_calls" = "steelblue", "control2_calls" = "darkred"), labels=c("Focal Unit", "Control Unit (SBU 2"))+
                labs(y="Calls", x="Time")+ #labels the axes
                theme(  panel.grid.major = element_blank(), #eliminates the grid lines
                        panel.grid.minor = element_blank(), #eliminates the grid lines
                        axis.line = element_line(colour = "black", size = 0.4, #changes settings for the y- and x-axes lines
                                    linetype = 1, lineend = "butt"),
                        panel.background = element_blank(),
                        legend.position = c(1,1),
                        legend.justification = c("right", "top"),
                        legend.direction = "vertical",
                        legend.box.just = "right")+
                  geom_vline(xintercept=oscDataWeeklyWide$ymd[as.numeric(oscDataWeeklyWide[oscDataWeeklyWide$community_launch==1,"trend"][1,])], 
                             color="darkgreen") #creates a vertical line where the community launch was
  
  print(callComparison)
```


############################################
############ Fuzzy Matching ################
############################################
```{r}
hh_data_matching2 <- stringdist_left_join(hh_data_matching, moby_data, 
                by='game_platform', #match based on name and platform combination (otherwise it drops observations because it only searches for a match of the game name, which are fewer than the combi of name and platform)
                method = "jw", #use jw distance metric
                max_dist=99, 
                distance_col='dist') %>% group_by(game_platform.x) %>% filter(dist==min(dist)) %>% 
```




############################################
############ TIPPS & TRICKS ################
############################################
```{r}
- Do not implement for-loops on large dataframes! The trick is to convert the columns or frames you have to vector or matrix because R can access these much faster in for-loops
- Arrays can only hold the same number of columns and rows for each of the array dimensions. This works if we have the same independent variables for each array (each equation), but it does not if we have different ones (e.g., for our ECM SUR in the online service communities project). You can then just store the variables in lists instead of arrays, where each list element contains a matrix of independent variables.

```




############################################
######## MODELING ##########################
############################################

# Cluster-robust standard errors
```{r}
# Calculate Cluster-Robust Standard Errors
      X <- model.matrix(outcome)
      u2 <- residuals(outcome)^2
      XDX <- 0
      ## One needs to calculate X'DX. But due to the fact that
      ## D is huge (NxN), it is better to do it with a cycle.
        for(i in 1:nrow(X)) {
          XDX <- XDX + u2[i]*X[i,]%*%t(X[i,])  #t is the transposing function
        }
        
      # inverse(X'X)
        XX1 <- solve(t(X)%*%X,tol = 1e-100)
        
      # Sandwich Variance calculation (Bread x meat x Bread)
        varcovar <- XX1 %*% XDX %*% XX1
        
        # adjust degrees of freedom 
        dfc_r <- sqrt(nrow(X))/sqrt(nrow(X)-ncol(X))
        
        # Standard errors of the coefficient estimates are the
        # square roots of the diagonal elements
        rstdh <- dfc_r*sqrt(diag(varcovar))
      # Calculating new t-values
        beta_coefficients <-summary(outcome)$coefficients 
```

# Sample selection by hand using Inverse Mills Ratio
```{r}
selection_equation <- glm(disneyadopter[1:N] ~ disney_sym[1:N]+ pixar[1:N]+ starwars[1:N]
+ geschlecht[1:N]+alter[1:N]+ bildungsgruppe[1:N]+ hhne[1:N]+ personen[1:N]+ internet_speed2[1:N]+ quality_ges[1:N]+  overload_ges[1:N]+ fragment_ges[1:N]+ nostalgia[1:N]+ systemrelevant[1:N]+ kurzarbeit[1:N]+  corona_akt_4[1:N]+ corona_akt_3[1:N]+  corona_akt_5[1:N]+ involvement[1:N]+ innovation_cat[1:N], data=disney2, family=binomial(link="probit"))
      summary(selection_equation)
      predicted_values <- predict(selection_equation)

      id <- disney2$id
      disneyAdoption <- disney2$disneyadopter #disney_stream (= alle diejenigen, die von Disney gehÃ¶rt haben)
      lambda=c()
      for (i in 1:NT) {
        if(disneyAdoption[i]==1)  {
      lambda[i]= dnorm(predicted_values[id[i]])/pnorm(predicted_values[id[i]]) #This is the inverse Mills ratio (but for all observations)
        }
        else {
      lambda[i]= -dnorm(predicted_values[id[i]])/(1-pnorm(predicted_values)[id[i]])
        }
      }
disney2$dlambda <- lambda #for the split sample analyses, I need to include it in the disney dataset to get the right filters
      
outcome <- lm(y ~ disney2$time* disney2$disneyadopter+lambda)
summary(outcome) 

clusterMat <- cluster.vcov(outcome, disney2$id)
coeftest(outcome, vcov=clusterMat)
coeftest(outcome, vcov=vcovHAC(outcome, order.by = disney2$id, prewhite = TRUE))
```






